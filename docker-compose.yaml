
x-airflow-env: &airflow-env
  PYTHONPATH: /opt/airflow
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow_postgres:5432/${AIRFLOW_POSTGRES_DB}
  AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow_postgres:5432/${AIRFLOW_POSTGRES_DB}
  AIRFLOW__CORE__LOAD_EXAMPLES: "false"
  AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
  AIRFLOW__API__BASE_URL: http://host.docker.internal:8080
  AIRFLOW__WEBSERVER__BASE_URL: http://host.docker.internal:8080
  AIRFLOW__API_AUTH__JWT_SECRET: ${AIRFLOW_API_JWT_SECRET}

x-airflow-common: &airflow-common
  build: .
  env_file:
    - .env
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/sql:/opt/airflow/sql
    - ./airflow/data:/opt/airflow/data
    - ./utils:/opt/airflow/utils
    - ./dbt:/opt/dbt
  depends_on:
    - airflow_postgres
    - redis

services:

  airflow_postgres:
    image: postgres:16
    container_name: metadata-postgres
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${AIRFLOW_POSTGRES_USER}
      POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD}
      POSTGRES_DB: ${AIRFLOW_POSTGRES_DB}
    volumes:
      - airflow_pg_data:/var/lib/postgresql/data
    extra_hosts:
    - "host.docker.internal:host-gateway"

  dwh_postgres:
    image: postgres:16
    container_name: dwh-postgres
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5433:5432"
    volumes:
      - dwh_pg_data:/var/lib/postgresql/data
    extra_hosts:
    - "host.docker.internal:host-gateway"

  redis:
    image: redis:7
    container_name: airflow-redis
    ports:
      - "6379:6379"
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    restart: "no"
    environment:
      <<: *airflow-env
      _AIRFLOW_DB_MIGRATE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USERNAME}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD}
      _AIRFLOW_WWW_USER_FIRSTNAME: ${AIRFLOW_ADMIN_FIRSTNAME}
      _AIRFLOW_WWW_USER_LASTNAME: ${AIRFLOW_ADMIN_LASTNAME}
      _AIRFLOW_WWW_USER_EMAIL: ${AIRFLOW_ADMIN_EMAIL}
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-apiserver:
    <<: *airflow-common
    container_name: airflow-apiserver
    command: api-server
    environment:
      <<: *airflow-env
    ports:
      - "8080:8080"
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    environment:
      <<: *airflow-env
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-worker:
    <<: *airflow-common
    container_name: airflow-worker
    command: celery worker
    environment:
      <<: *airflow-env
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-triggerer:
    <<: *airflow-common
    container_name: airflow-triggerer
    command: triggerer
    environment:
      <<: *airflow-env
    extra_hosts:
    - "host.docker.internal:host-gateway"

  airflow-dag-processor:
    <<: *airflow-common
    container_name: airflow-dag-processor
    command: dag-processor
    environment:
      <<: *airflow-env
    extra_hosts:
    - "host.docker.internal:host-gateway"

  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.5
    container_name: dbt
    env_file:
      - .env
    volumes:
      - ./dbt:/usr/app
    working_dir: /usr/app
    depends_on:
      - dwh_postgres

volumes:
  airflow_pg_data:
  dwh_pg_data: